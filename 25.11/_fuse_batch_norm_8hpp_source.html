<!-- HTML header for doxygen 1.8.17-->
<!-- Copyright © 2023-2024 Arm Ltd and Contributors. -->
<!-- SPDX-License-Identifier: MIT -->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.14.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Arm NN: src/armnn/optimizations/FuseBatchNorm.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <img alt="ArmNN" src="Arm_NN_horizontal_blue.png" style="max-width: 15rem; margin-top: .5rem; margin-left 13px"/>
  <td id="projectalign" style="padding-left: 0.9em;">
   <div id="projectname">
   &#160;<span id="projectnumber">25.11</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.14.0 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search/",'.html');
</script>
<script type="text/javascript">
$(function() { codefold.init(); });
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search',true);
  $(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(function(){initNavTree('_fuse_batch_norm_8hpp_source.html','',''); });
</script>
<div id="container">
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">FuseBatchNorm.hpp</div></div>
</div><!--header-->
<div class="contents">
<a href="_fuse_batch_norm_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span><span class="comment">//</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="comment">// Copyright © 2020,2022 Arm Ltd and Contributors. All rights reserved.</span></div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="comment">// SPDX-License-Identifier: MIT</span></div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="comment">//</span></div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span> </div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="preprocessor">#pragma once</span></div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span> </div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="preprocessor">#include &quot;<a class="code" href="_optimization_8hpp.html">Optimization.hpp</a>&quot;</span></div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span><span class="preprocessor">#include &lt;<a class="code" href="_data_layout_indexed_8hpp.html">armnnUtils/DataLayoutIndexed.hpp</a>&gt;</span></div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span><span class="preprocessor">#include &lt;<a class="code" href="_resolve_type_8hpp.html">ResolveType.hpp</a>&gt;</span></div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span> </div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span><span class="keyword">namespace </span><a class="code hl_namespace" href="namespacearmnn.html">armnn</a></div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span>{</div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="keyword">namespace </span><a class="code hl_namespace" href="namespacearmnn_1_1optimizations.html">optimizations</a></div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span>{</div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span> </div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span><span class="keyword">template</span>&lt;<span class="keyword">typename</span> ConvLayer, <a class="code hl_enumeration" href="namespacearmnn.html#ad8ed01ff3ff33333d8e19db4d2818bb6">armnn::DataType</a> ArmnnType,</div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span>         <span class="keyword">typename</span> T = <a class="code hl_typedef" href="namespacearmnn.html#a0743ed5e860c316a20b68ca96301b411">armnn::ResolveType&lt;ArmnnType&gt;</a>&gt;</div>
<div class="foldopen" id="foldopen00019" data-start="{" data-end="};">
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno"><a class="line" href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.html">   19</a></span><span class="keyword">class </span><a class="code hl_function" href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.html#abe49327783cb8bdc12c085c987db14db">FuseBatchNorm</a></div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span>{</div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span><span class="keyword">public</span>:<span class="comment"></span></div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span><span class="comment">    /// Run for every exclusive connection between any base Convolution layer and a child BatchNorm layer for not</span></div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span><span class="comment">    /// quantized layers.</span></div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span><span class="comment">    /// The child will be removed, the base will be removed if it&#39;s left unconnected. A new Convolution layer will</span></div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span><span class="comment">    /// be added, its weights and bias will be calculated using the weights and bias of the base Convolution layer</span></div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno">   26</span><span class="comment">    /// combined with the parameters of the child BatchNorm layer.</span></div>
<div class="foldopen" id="foldopen00027" data-start="{" data-end="}">
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno"><a class="line" href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.html#a5a8476ffc04ce7460bb09ad50d1d23de">   27</a></span>    <span class="keywordtype">void</span> <a class="code hl_function" href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.html#a5a8476ffc04ce7460bb09ad50d1d23de">Run</a>(<a class="code hl_class" href="classarmnn_1_1_graph.html">Graph</a>&amp; graph, <a class="code hl_class" href="classarmnn_1_1_input_slot.html">InputSlot</a>&amp; connection)<span class="keyword"> const</span></div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno">   28</span><span class="keyword">    </span>{</div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno">   29</span>        <a class="code hl_class" href="classarmnn_1_1_layer.html">Layer</a>&amp; base = connection.<a class="code hl_function" href="classarmnn_1_1_input_slot.html#a9ae1c86210bf4715afe24f9b2bcadf03">GetConnectedOutputSlot</a>()-&gt;<a class="code hl_function" href="classarmnn_1_1_output_slot.html#a8cc88357e965a69501e0b2bdec768319">GetOwningLayer</a>();</div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span>        <a class="code hl_class" href="classarmnn_1_1_layer.html">Layer</a>&amp; child = connection.<a class="code hl_function" href="classarmnn_1_1_input_slot.html#a8cc88357e965a69501e0b2bdec768319">GetOwningLayer</a>();</div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno">   31</span> </div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno">   32</span>        <span class="keywordtype">bool</span> depthwise = (base.<a class="code hl_function" href="classarmnn_1_1_layer.html#ad8e15c530c929ab823d89ae9fd2d3f11">GetType</a>() == <a class="code hl_enumvalue" href="namespacearmnn.html#a56943a0946e5f15e5e58054b8e7a04a4af97adbfc88b7012a0243215b1076e7e7">LayerType::DepthwiseConvolution2d</a>);</div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno">   33</span> </div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno">   34</span>        <a class="code hl_define" href="_assert_8hpp.html#a5698be69cbd5dfe6c28fcd9867e8cbed">ARMNN_ASSERT</a>(base.<a class="code hl_function" href="classarmnn_1_1_layer.html#ad8e15c530c929ab823d89ae9fd2d3f11">GetType</a>() == <a class="code hl_enumvalue" href="namespacearmnn.html#a56943a0946e5f15e5e58054b8e7a04a4adb033d2f81b68f9a17e8f62de69fed4a">LayerType::Convolution2d</a> || depthwise);</div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno">   35</span>        <a class="code hl_define" href="_assert_8hpp.html#a5698be69cbd5dfe6c28fcd9867e8cbed">ARMNN_ASSERT</a>(child.<a class="code hl_function" href="classarmnn_1_1_layer.html#ad8e15c530c929ab823d89ae9fd2d3f11">GetType</a>() == <a class="code hl_enumvalue" href="namespacearmnn.html#a56943a0946e5f15e5e58054b8e7a04a4ae4743c3ec15d1d84169b17264634692e">LayerType::BatchNormalization</a>);</div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno">   36</span> </div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno">   37</span>        <span class="keywordflow">if</span> (base.<a class="code hl_function" href="classarmnn_1_1_layer.html#aea909c7327109228ef618d459015def3">GetDataType</a>() == ArmnnType &amp;&amp; child.<a class="code hl_function" href="classarmnn_1_1_layer.html#aea909c7327109228ef618d459015def3">GetDataType</a>() == ArmnnType)</div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno">   38</span>        {</div>
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno">   39</span>            <a class="code hl_class" href="classarmnn_1_1_output_slot.html">OutputSlot</a>* parentOut = base.<a class="code hl_function" href="classarmnn_1_1_layer.html#a247a09d09842358d1952cda6a3a165b5">GetInputSlot</a>(0).<a class="code hl_function" href="classarmnn_1_1_input_slot.html#a9ae1c86210bf4715afe24f9b2bcadf03">GetConnectedOutputSlot</a>();</div>
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno">   40</span>            <span class="keyword">auto</span> convLayer = <a class="code hl_function" href="namespacearmnn.html#aa61aa94683e990075a26c5e56ddc85eb">PolymorphicDowncast&lt;ConvLayer*&gt;</a>(&amp;base);</div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span>            <span class="keyword">auto</span> batchNormLayer = <a class="code hl_function" href="namespacearmnn.html#aa61aa94683e990075a26c5e56ddc85eb">PolymorphicDowncast&lt;BatchNormalizationLayer*&gt;</a>(&amp;child);</div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno">   42</span> </div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno">   43</span>            <span class="comment">// Read convolution and batch norm parameters</span></div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno">   44</span>            <a class="code hl_struct" href="structarmnn_1_1_batch_normalization_descriptor.html">BatchNormalizationDescriptor</a> batchNormDescriptor = batchNormLayer-&gt;GetParameters();</div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span>            <span class="keyword">auto</span> epsilon = batchNormDescriptor.<a class="code hl_variable" href="structarmnn_1_1_batch_normalization_descriptor.html#a11c821c7524251004a72ed13c510853c">m_Eps</a>;</div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno">   46</span>            <a class="code hl_function" href="namespacearmnn.html#aff5e3bc27829d0cdb153a80dce50fa34">IgnoreUnused</a>(epsilon);</div>
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno">   47</span> </div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno">   48</span>            <a class="code hl_class" href="classarmnn_1_1_const_tensor.html">ConstTensor</a> betaTensor(batchNormLayer-&gt;m_Beta-&gt;GetTensorInfo(), batchNormLayer-&gt;m_Beta-&gt;Map(<span class="keyword">true</span>));</div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno">   49</span>            <a class="code hl_class" href="classarmnn_1_1_const_tensor.html">ConstTensor</a> gammaTensor(batchNormLayer-&gt;m_Gamma-&gt;GetTensorInfo(), batchNormLayer-&gt;m_Gamma-&gt;Map(<span class="keyword">true</span>));</div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno">   50</span>            <a class="code hl_class" href="classarmnn_1_1_const_tensor.html">ConstTensor</a> meanTensor(batchNormLayer-&gt;m_Mean-&gt;GetTensorInfo(), batchNormLayer-&gt;m_Mean-&gt;Map(<span class="keyword">true</span>));</div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span>            <a class="code hl_class" href="classarmnn_1_1_const_tensor.html">ConstTensor</a> varTensor(batchNormLayer-&gt;m_Variance-&gt;GetTensorInfo(), batchNormLayer-&gt;m_Variance-&gt;Map(<span class="keyword">true</span>));</div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span> </div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span>            <span class="keyword">auto</span> convDescriptor = convLayer-&gt;GetParameters();</div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span>            <a class="code hl_class" href="classarmnn_1_1_const_tensor.html">ConstTensor</a> weightsTensor;</div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno">   55</span>            <a class="code hl_define" href="_assert_8hpp.html#a91c4dfde57907d7698c7531785690a7f">ARMNN_ASSERT_MSG</a>(convLayer-&gt;GetInputSlots()[1].GetConnection() != <span class="keyword">nullptr</span>,</div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno">   56</span>                             <span class="stringliteral">&quot;FuseBatchNorm: Weight data should not be null.&quot;</span>);</div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span> </div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span>            <a class="code hl_class" href="classarmnn_1_1_constant_layer.html">ConstantLayer</a>* weightLayer = <a class="code hl_function" href="namespacearmnn.html#aa61aa94683e990075a26c5e56ddc85eb">PolymorphicDowncast&lt;ConstantLayer*&gt;</a>(</div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span>                                        &amp;base.<a class="code hl_function" href="classarmnn_1_1_layer.html#a247a09d09842358d1952cda6a3a165b5">GetInputSlot</a>(1).<a class="code hl_function" href="classarmnn_1_1_input_slot.html#a9ae1c86210bf4715afe24f9b2bcadf03">GetConnectedOutputSlot</a>()-&gt;<a class="code hl_function" href="classarmnn_1_1_output_slot.html#a8cc88357e965a69501e0b2bdec768319">GetOwningLayer</a>());</div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno">   60</span> </div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span>            weightsTensor = <a class="code hl_class" href="classarmnn_1_1_const_tensor.html">ConstTensor</a>(weightLayer-&gt;<a class="code hl_variable" href="classarmnn_1_1_constant_layer.html#ad0c4b8ee0efd8f9336571cbeab8a53fe">m_LayerOutput</a>-&gt;GetTensorInfo(),</div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span>                                        weightLayer-&gt;<a class="code hl_variable" href="classarmnn_1_1_constant_layer.html#ad0c4b8ee0efd8f9336571cbeab8a53fe">m_LayerOutput</a>-&gt;Map(<span class="keyword">true</span>));</div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span> </div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span>            <a class="code hl_class" href="classarmnn_utils_1_1_data_layout_indexed.html">armnnUtils::DataLayoutIndexed</a> dataLayout(convDescriptor.m_DataLayout);</div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span>            <span class="keyword">auto</span> weightsShape = weightsTensor.<a class="code hl_function" href="classarmnn_1_1_base_tensor.html#a265f6f3ff9402ba2499541b8c2348e34">GetInfo</a>().<a class="code hl_function" href="classarmnn_1_1_tensor_info.html#a0b28207ca7de967c2da4113bdec9518f">GetShape</a>();</div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span>            <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputChannels   = parentOut-&gt;<a class="code hl_function" href="classarmnn_1_1_output_slot.html#ada2ad7d1caeeb4ef6195c8925fad6a65">GetTensorInfo</a>().<a class="code hl_function" href="classarmnn_1_1_tensor_info.html#a0b28207ca7de967c2da4113bdec9518f">GetShape</a>()[dataLayout.<a class="code hl_function" href="classarmnn_utils_1_1_data_layout_indexed.html#a861b2621ee46e4b63379988b360b8cd9">GetChannelsIndex</a>()];</div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span>            <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> depthMultiplier = depthwise ? weightsShape[3] / inputChannels : 1;</div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span>            <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> outputChannels  = depthwise ? weightsShape[3] : weightsShape[0];</div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span>            <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> weightsHeight   = depthwise ? weightsShape[1] :</div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span>                                                 weightsShape[dataLayout.<a class="code hl_function" href="classarmnn_utils_1_1_data_layout_indexed.html#a61c00316c443adc233c24e85c6c5b740">GetHeightIndex</a>()];</div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span>            <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> weightsWidth    = depthwise ? weightsShape[2] :</div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span>                                                 weightsShape[dataLayout.<a class="code hl_function" href="classarmnn_utils_1_1_data_layout_indexed.html#a414e6f95548e6f7a01d5028b55ad3941">GetWidthIndex</a>()];</div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span> </div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span>            <span class="keyword">const</span> <span class="keyword">auto</span>* weightsBuffer = <span class="keyword">static_cast&lt;</span><span class="keyword">const </span>T*<span class="keyword">&gt;</span>(weightsTensor.<a class="code hl_function" href="classarmnn_1_1_base_tensor.html#aa81f67ac64f0c249e26499600c45d996">GetMemoryArea</a>());</div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span>            <span class="keyword">const</span> <span class="keyword">auto</span>* betaBuffer    = <span class="keyword">static_cast&lt;</span><span class="keyword">const </span>T*<span class="keyword">&gt;</span>(betaTensor.<a class="code hl_function" href="classarmnn_1_1_base_tensor.html#aa81f67ac64f0c249e26499600c45d996">GetMemoryArea</a>());</div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span>            <span class="keyword">const</span> <span class="keyword">auto</span>* gammaBuffer   = <span class="keyword">static_cast&lt;</span><span class="keyword">const </span>T*<span class="keyword">&gt;</span>(gammaTensor.<a class="code hl_function" href="classarmnn_1_1_base_tensor.html#aa81f67ac64f0c249e26499600c45d996">GetMemoryArea</a>());</div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span>            <span class="keyword">const</span> <span class="keyword">auto</span>* meanBuffer    = <span class="keyword">static_cast&lt;</span><span class="keyword">const </span>T*<span class="keyword">&gt;</span>(meanTensor.<a class="code hl_function" href="classarmnn_1_1_base_tensor.html#aa81f67ac64f0c249e26499600c45d996">GetMemoryArea</a>());</div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span>            <span class="keyword">const</span> <span class="keyword">auto</span>* varBuffer     = <span class="keyword">static_cast&lt;</span><span class="keyword">const </span>T*<span class="keyword">&gt;</span>(varTensor.<a class="code hl_function" href="classarmnn_1_1_base_tensor.html#aa81f67ac64f0c249e26499600c45d996">GetMemoryArea</a>());</div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span> </div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span>            std::vector&lt;T&gt; weightsVector (weightsBuffer, weightsBuffer + weightsTensor.<a class="code hl_function" href="classarmnn_1_1_base_tensor.html#a8846406ac37fbd2204f0be16ee05d5b7">GetNumElements</a>());</div>
<div class="line"><a id="l00081" name="l00081"></a><span class="lineno">   81</span>            std::vector&lt;T&gt; betaVector    (betaBuffer, betaBuffer + betaTensor.<a class="code hl_function" href="classarmnn_1_1_base_tensor.html#a8846406ac37fbd2204f0be16ee05d5b7">GetNumElements</a>());</div>
<div class="line"><a id="l00082" name="l00082"></a><span class="lineno">   82</span>            std::vector&lt;T&gt; gammaVector   (gammaBuffer, gammaBuffer + gammaTensor.<a class="code hl_function" href="classarmnn_1_1_base_tensor.html#a8846406ac37fbd2204f0be16ee05d5b7">GetNumElements</a>());</div>
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno">   83</span>            std::vector&lt;T&gt; meanVector    (meanBuffer, meanBuffer + meanTensor.<a class="code hl_function" href="classarmnn_1_1_base_tensor.html#a8846406ac37fbd2204f0be16ee05d5b7">GetNumElements</a>());</div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span>            std::vector&lt;T&gt; varianceVector(varBuffer, varBuffer + varTensor.<a class="code hl_function" href="classarmnn_1_1_base_tensor.html#a8846406ac37fbd2204f0be16ee05d5b7">GetNumElements</a>());</div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span> </div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span>            <span class="comment">// fusedWeights = ( gamma * weights ) / ( std - epsilon);</span></div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span>            std::vector&lt;T&gt; fusedWeightsVector(weightsVector.size());</div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span> </div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span>            <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> cInput = 0; cInput &lt; inputChannels; ++cInput)</div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span>            {</div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span>                <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> cOut = 0; cOut &lt; outputChannels; ++cOut)</div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span>                {</div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span>                    T mult = gammaVector[cOut] / <span class="keyword">static_cast&lt;</span>T<span class="keyword">&gt;</span>(sqrtf(varianceVector[cOut] + epsilon));</div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span> </div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span>                    <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> h = 0; h &lt; weightsHeight; ++h)</div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span>                    {</div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span>                        <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> w = 0; w &lt; weightsWidth; ++w)</div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span>                        {</div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span>                            <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> weightsIdx = 0;</div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span> </div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span>                            <span class="keywordflow">if</span> (depthwise)</div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span>                            {</div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span>                                cInput = cOut / depthMultiplier;</div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span>                                weightsIdx = w * outputChannels + cOut +</div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span>                                             h * weightsWidth * outputChannels;</div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span>                            }</div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span>                            <span class="keywordflow">else</span> <span class="keywordflow">if</span> (convDescriptor.m_DataLayout == <a class="code hl_enumvalue" href="namespacearmnn.html#ad1d5cce2d9e9a5d61c243e5c989112e0ad066db54b89b0912e7e7c6da51e2da51">DataLayout::NHWC</a>)</div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span>                            {</div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span>                                weightsIdx = cOut * weightsHeight * weightsWidth * inputChannels +</div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span>                                             h * weightsWidth * inputChannels +</div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno">  111</span>                                             w * inputChannels +</div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span>                                             cInput;</div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span>                            }</div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span>                            <span class="keywordflow">else</span></div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span>                            {</div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span>                                weightsIdx = cOut * weightsWidth * weightsHeight * inputChannels +</div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span>                                             cInput * weightsWidth * weightsHeight +</div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno">  118</span>                                             h * weightsWidth +</div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span>                                             w;</div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span>                            }</div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span>                            fusedWeightsVector[weightsIdx] = mult * weightsVector[weightsIdx];</div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span>                        }</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span>                    }</div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span>                }</div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span>            }</div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span>            <a class="code hl_class" href="classarmnn_1_1_const_tensor.html">ConstTensor</a> fusedWeightsTensor(weightsTensor.<a class="code hl_function" href="classarmnn_1_1_base_tensor.html#a265f6f3ff9402ba2499541b8c2348e34">GetInfo</a>(), fusedWeightsVector);</div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span> </div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span>            <span class="comment">//  fusedBias = (gamma * (bias - mean)) / (variance - epsilon) + beta;</span></div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span>            std::vector&lt;T&gt; fusedBiasVector(outputChannels);</div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span>            <span class="keywordtype">bool</span> biasWasEnabledBeforeOpt = convDescriptor.m_BiasEnabled;</div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno">  131</span>            <span class="keywordflow">if</span> (biasWasEnabledBeforeOpt)</div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span>            {</div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span>                <a class="code hl_class" href="classarmnn_1_1_const_tensor.html">ConstTensor</a> biasTensor;</div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span>                <a class="code hl_define" href="_assert_8hpp.html#a91c4dfde57907d7698c7531785690a7f">ARMNN_ASSERT_MSG</a>(convLayer-&gt;GetInputSlots()[2].GetConnection() != <span class="keyword">nullptr</span>,</div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span>                                 <span class="stringliteral">&quot;FuseBatchNorm: Bias data should not be null if bias is enabled.&quot;</span>);</div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span> </div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span>                <a class="code hl_class" href="classarmnn_1_1_constant_layer.html">ConstantLayer</a>* biasLayer = <a class="code hl_function" href="namespacearmnn.html#aa61aa94683e990075a26c5e56ddc85eb">PolymorphicDowncast&lt;ConstantLayer*&gt;</a>(</div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span>                                                &amp;base.<a class="code hl_function" href="classarmnn_1_1_layer.html#a247a09d09842358d1952cda6a3a165b5">GetInputSlot</a>(2).<a class="code hl_function" href="classarmnn_1_1_input_slot.html#a9ae1c86210bf4715afe24f9b2bcadf03">GetConnectedOutputSlot</a>()-&gt;<a class="code hl_function" href="classarmnn_1_1_output_slot.html#a8cc88357e965a69501e0b2bdec768319">GetOwningLayer</a>());</div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span> </div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span>                biasTensor = <a class="code hl_class" href="classarmnn_1_1_const_tensor.html">ConstTensor</a>(biasLayer-&gt;<a class="code hl_variable" href="classarmnn_1_1_constant_layer.html#ad0c4b8ee0efd8f9336571cbeab8a53fe">m_LayerOutput</a>-&gt;GetTensorInfo(),</div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span>                                         biasLayer-&gt;<a class="code hl_variable" href="classarmnn_1_1_constant_layer.html#ad0c4b8ee0efd8f9336571cbeab8a53fe">m_LayerOutput</a>-&gt;Map(<span class="keyword">true</span>));</div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span> </div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span>                <span class="keyword">const</span> <span class="keyword">auto</span>* biasBuffer = <span class="keyword">static_cast&lt;</span><span class="keyword">const </span>T*<span class="keyword">&gt;</span>(biasTensor.<a class="code hl_function" href="classarmnn_1_1_base_tensor.html#aa81f67ac64f0c249e26499600c45d996">GetMemoryArea</a>());</div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno">  144</span>                std::vector&lt;T&gt; biasVector(biasBuffer, biasBuffer + biasTensor.<a class="code hl_function" href="classarmnn_1_1_base_tensor.html#a8846406ac37fbd2204f0be16ee05d5b7">GetNumElements</a>());</div>
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno">  145</span> </div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span>                <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> cOut = 0; cOut &lt; outputChannels; ++cOut)</div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span>                {</div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span>                    fusedBiasVector[cOut] = ((gammaVector[cOut] * (biasVector[cOut] - meanVector[cOut])) /</div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span>                                             sqrtf(varianceVector[cOut] + epsilon)) + betaVector[cOut];</div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span>                }</div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno">  151</span>            }</div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno">  152</span>            <span class="keywordflow">else</span></div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span>            {</div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span>                convDescriptor.m_BiasEnabled = <span class="keyword">true</span>;</div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span>                std::vector&lt;T&gt; biasVector(outputChannels, T(0));</div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span> </div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span>                <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> cOut = 0; cOut &lt; outputChannels; ++cOut)</div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span>                {</div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span>                    fusedBiasVector[cOut] = ((gammaVector[cOut] * (biasVector[cOut] - meanVector[cOut])) /</div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno">  160</span>                                             sqrtf(varianceVector[cOut] + epsilon)) + betaVector[cOut];</div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno">  161</span>                }</div>
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno">  162</span>            }</div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno">  163</span>            <a class="code hl_class" href="classarmnn_1_1_const_tensor.html">ConstTensor</a> fusedBiasTensor(<a class="code hl_class" href="classarmnn_1_1_tensor_info.html">TensorInfo</a>({outputChannels}, ArmnnType, 0.0f, 0, <span class="keyword">true</span>), fusedBiasVector);</div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span> </div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span>            <span class="comment">// Insert the new convolution layer that has batch norm parameters fused into</span></div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span>            <span class="keyword">const</span> std::string name = std::string(<span class="stringliteral">&quot;fused-&quot;</span>) + child.<a class="code hl_function" href="classarmnn_1_1_layer.html#ad47edad463024345ce1409153c259215">GetName</a>() + std::string(<span class="stringliteral">&quot;-into-&quot;</span>) + base.<a class="code hl_function" href="classarmnn_1_1_layer.html#ad47edad463024345ce1409153c259215">GetName</a>();</div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span>            <span class="keyword">auto</span>&amp; newConv2dLayer = *graph.<a class="code hl_function" href="classarmnn_1_1_graph.html#a3ff30c6669fdc69de1f5be1f89bacc3f">InsertNewLayer</a>&lt;ConvLayer&gt;(base.<a class="code hl_function" href="classarmnn_1_1_layer.html#a247a09d09842358d1952cda6a3a165b5">GetInputSlot</a>(0),</div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span>                                                                    convDescriptor,</div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span>                                                                    name.c_str());</div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno">  170</span> </div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno">  171</span>            <span class="comment">// Connect weights and bias from old to new Conv2d layer</span></div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno">  172</span>            <span class="comment">// This optimization will always have 3 input slots on the Conv2d base layer</span></div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span>            <span class="keywordflow">if</span> (newConv2dLayer.GetNumInputSlots() &gt; 1)</div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span>            {</div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span>                <span class="comment">// Remove old connection and connect to new layer2d</span></div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno">  176</span>                weightLayer-&gt;<a class="code hl_function" href="classarmnn_1_1_layer.html#a84d01c23dc71a5502a10c0f97f19ba1f">GetOutputSlot</a>(0).<a class="code hl_function" href="classarmnn_1_1_output_slot.html#ac72a192dfcfa19e6ce826f99b415a11d">Disconnect</a>(base.<a class="code hl_function" href="classarmnn_1_1_layer.html#a247a09d09842358d1952cda6a3a165b5">GetInputSlot</a>(1));</div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span>                weightLayer-&gt;<a class="code hl_function" href="classarmnn_1_1_layer.html#a84d01c23dc71a5502a10c0f97f19ba1f">GetOutputSlot</a>(0).<a class="code hl_function" href="classarmnn_1_1_output_slot.html#adcfb97035799ea4c043f9ef370714815">Connect</a>(newConv2dLayer.GetInputSlot(1));</div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span>                weightLayer-&gt;<a class="code hl_variable" href="classarmnn_1_1_constant_layer.html#ad0c4b8ee0efd8f9336571cbeab8a53fe">m_LayerOutput</a> = std::make_unique&lt;ScopedTensorHandle&gt;(fusedWeightsTensor);</div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span> </div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span>                <span class="comment">// Move bias const layers as normal if it was enabled before the optimisation</span></div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span>                <a class="code hl_class" href="classarmnn_1_1_constant_layer.html">ConstantLayer</a>* biasLayer;</div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span>                <span class="keywordflow">if</span> (biasWasEnabledBeforeOpt)</div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span>                {</div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span>                    biasLayer = <a class="code hl_function" href="namespacearmnn.html#aa61aa94683e990075a26c5e56ddc85eb">PolymorphicDowncast&lt;ConstantLayer*&gt;</a>(</div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno">  185</span>                        &amp;base.<a class="code hl_function" href="classarmnn_1_1_layer.html#a247a09d09842358d1952cda6a3a165b5">GetInputSlot</a>(2).<a class="code hl_function" href="classarmnn_1_1_input_slot.html#a9ae1c86210bf4715afe24f9b2bcadf03">GetConnectedOutputSlot</a>()-&gt;<a class="code hl_function" href="classarmnn_1_1_output_slot.html#a8cc88357e965a69501e0b2bdec768319">GetOwningLayer</a>());</div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span>                    <span class="comment">// Remove old connection and connect to new layer2d</span></div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span>                    biasLayer-&gt;<a class="code hl_function" href="classarmnn_1_1_layer.html#a84d01c23dc71a5502a10c0f97f19ba1f">GetOutputSlot</a>(0).<a class="code hl_function" href="classarmnn_1_1_output_slot.html#ac72a192dfcfa19e6ce826f99b415a11d">Disconnect</a>(base.<a class="code hl_function" href="classarmnn_1_1_layer.html#a247a09d09842358d1952cda6a3a165b5">GetInputSlot</a>(2));</div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span>                    biasLayer-&gt;<a class="code hl_function" href="classarmnn_1_1_layer.html#a84d01c23dc71a5502a10c0f97f19ba1f">GetOutputSlot</a>(0).<a class="code hl_function" href="classarmnn_1_1_output_slot.html#adcfb97035799ea4c043f9ef370714815">Connect</a>(newConv2dLayer.GetInputSlot(2));</div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span> </div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span>                }</div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span>                <span class="comment">// Otherwise create a new bias layer and add to the new convolution2d</span></div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span>                <span class="keywordflow">else</span></div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span>                {</div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span>                    <span class="comment">// Add in bias constant layer</span></div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span>                    biasLayer = graph.<a class="code hl_function" href="classarmnn_1_1_graph.html#a7563c5b899e7d0ada08fd0fdb202f205">AddLayer</a>&lt;<a class="code hl_class" href="classarmnn_1_1_constant_layer.html">ConstantLayer</a>&gt;(<span class="stringliteral">&quot;Bias&quot;</span>);</div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span>                    biasLayer-&gt;<a class="code hl_function" href="classarmnn_1_1_layer.html#a84d01c23dc71a5502a10c0f97f19ba1f">GetOutputSlot</a>(0).<a class="code hl_function" href="classarmnn_1_1_output_slot.html#a7e5c5771d741dd5473989047a9314728">SetTensorInfo</a>(fusedBiasTensor.<a class="code hl_function" href="classarmnn_1_1_base_tensor.html#a265f6f3ff9402ba2499541b8c2348e34">GetInfo</a>());</div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span>                    biasLayer-&gt;<a class="code hl_function" href="classarmnn_1_1_layer.html#a84d01c23dc71a5502a10c0f97f19ba1f">GetOutputSlot</a>(0).<a class="code hl_function" href="classarmnn_1_1_output_slot.html#adcfb97035799ea4c043f9ef370714815">Connect</a>(newConv2dLayer.GetInputSlot(2));</div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span>                }</div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span>                biasLayer-&gt;<a class="code hl_variable" href="classarmnn_1_1_constant_layer.html#ad0c4b8ee0efd8f9336571cbeab8a53fe">m_LayerOutput</a> = std::make_unique&lt;ScopedTensorHandle&gt;(<a class="code hl_class" href="classarmnn_1_1_const_tensor.html">ConstTensor</a>(fusedBiasTensor));</div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span>            }</div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span> </div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span> </div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span>            <span class="comment">// Reconnects with original parent.</span></div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span>            newConv2dLayer.GetOutputSlot().MoveAllConnections(*parentOut);</div>
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno">  205</span>            <span class="comment">// Parent is now the new convolution2d layer.</span></div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span>            parentOut = &amp;newConv2dLayer.GetOutputSlot();</div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno">  207</span> </div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span>            <span class="comment">// Moves connections in child output to parent layer.</span></div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span>            <span class="comment">// Child layer will be removed as it&#39;s left unconnected.</span></div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno">  210</span>            <span class="comment">// Base layer will be removed if left unconnected.</span></div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno">  211</span>            child.<a class="code hl_function" href="classarmnn_1_1_layer.html#a84d01c23dc71a5502a10c0f97f19ba1f">GetOutputSlot</a>().<a class="code hl_function" href="classarmnn_1_1_output_slot.html#a19d30f83e90f2612e6aec510715f790d">MoveAllConnections</a>(*parentOut);</div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno">  212</span>        }</div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno">  213</span>    }</div>
</div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span><span class="keyword">protected</span>:</div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno"><a class="line" href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.html#abe49327783cb8bdc12c085c987db14db">  215</a></span>    <a class="code hl_function" href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.html#abe49327783cb8bdc12c085c987db14db">FuseBatchNorm</a>()  = <span class="keywordflow">default</span>;</div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno"><a class="line" href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.html#a0ff9a790927b898d90261a8ea0e479e6">  216</a></span>    <a class="code hl_function" href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.html#a0ff9a790927b898d90261a8ea0e479e6">~FuseBatchNorm</a>() = <span class="keywordflow">default</span>;</div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span>};</div>
</div>
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno">  218</span> </div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno"><a class="line" href="namespacearmnn_1_1optimizations.html#adbe678295995f56256c7c2d40c6e3e5d">  219</a></span><span class="keyword">using </span><a class="code hl_typedef" href="namespacearmnn_1_1optimizations.html#adbe678295995f56256c7c2d40c6e3e5d">FuseBatchNormIntoConvolution2DFloat32</a> =</div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span>        <a class="code hl_class" href="classarmnn_1_1_optimize_for_exclusive_connection.html">OptimizeForExclusiveConnection</a>&lt;<a class="code hl_class" href="classarmnn_1_1_convolution2d_layer.html">Convolution2dLayer</a>,</div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span>                                       <a class="code hl_class" href="classarmnn_1_1_batch_normalization_layer.html">BatchNormalizationLayer</a>,</div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span>                                       <a class="code hl_class" href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.html">FuseBatchNorm&lt;Convolution2dLayer, armnn::DataType::Float32&gt;</a>&gt;;</div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno">  223</span> </div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno"><a class="line" href="namespacearmnn_1_1optimizations.html#a51e4143e66bc9ba9636fb6880a18a3b3">  224</a></span><span class="keyword">using </span><a class="code hl_typedef" href="namespacearmnn_1_1optimizations.html#a51e4143e66bc9ba9636fb6880a18a3b3">FuseBatchNormIntoConvolution2DFloat16</a> =</div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span>        <a class="code hl_class" href="classarmnn_1_1_optimize_for_exclusive_connection.html">OptimizeForExclusiveConnection</a>&lt;<a class="code hl_class" href="classarmnn_1_1_convolution2d_layer.html">Convolution2dLayer</a>,</div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span>                                       <a class="code hl_class" href="classarmnn_1_1_batch_normalization_layer.html">BatchNormalizationLayer</a>,</div>
<div class="line"><a id="l00227" name="l00227"></a><span class="lineno">  227</span>                                       <a class="code hl_class" href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.html">FuseBatchNorm&lt;Convolution2dLayer, armnn::DataType::Float16&gt;</a>&gt;;</div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span> </div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno"><a class="line" href="namespacearmnn_1_1optimizations.html#aba46a6261e0026b6a35e85fed91f1e35">  229</a></span><span class="keyword">using </span><a class="code hl_typedef" href="namespacearmnn_1_1optimizations.html#aba46a6261e0026b6a35e85fed91f1e35">FuseBatchNormIntoDepthwiseConvolution2DFloat32</a> =</div>
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno">  230</span>        <a class="code hl_class" href="classarmnn_1_1_optimize_for_exclusive_connection.html">OptimizeForExclusiveConnection</a>&lt;<a class="code hl_class" href="classarmnn_1_1_depthwise_convolution2d_layer.html">DepthwiseConvolution2dLayer</a>,</div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span>                                       <a class="code hl_class" href="classarmnn_1_1_batch_normalization_layer.html">BatchNormalizationLayer</a>,</div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span>                                       <a class="code hl_class" href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.html">FuseBatchNorm&lt;DepthwiseConvolution2dLayer, armnn::DataType::Float32&gt;</a>&gt;;</div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span> </div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno"><a class="line" href="namespacearmnn_1_1optimizations.html#ab2d7602801c93779f038cda5e4850502">  234</a></span><span class="keyword">using </span><a class="code hl_typedef" href="namespacearmnn_1_1optimizations.html#ab2d7602801c93779f038cda5e4850502">FuseBatchNormIntoDepthwiseConvolution2DFloat16</a> =</div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span>        <a class="code hl_class" href="classarmnn_1_1_optimize_for_exclusive_connection.html">OptimizeForExclusiveConnection</a>&lt;<a class="code hl_class" href="classarmnn_1_1_depthwise_convolution2d_layer.html">DepthwiseConvolution2dLayer</a>,</div>
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno">  236</span>                                       <a class="code hl_class" href="classarmnn_1_1_batch_normalization_layer.html">BatchNormalizationLayer</a>,</div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno">  237</span>                                       <a class="code hl_class" href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.html">FuseBatchNorm&lt;DepthwiseConvolution2dLayer, armnn::DataType::Float16&gt;</a>&gt;;</div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno">  238</span> </div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno">  239</span>} <span class="comment">// namespace optimizations</span></div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span>} <span class="comment">// namespace armnn</span></div>
<div class="ttc" id="a_assert_8hpp_html_a5698be69cbd5dfe6c28fcd9867e8cbed"><div class="ttname"><a href="_assert_8hpp.html#a5698be69cbd5dfe6c28fcd9867e8cbed">ARMNN_ASSERT</a></div><div class="ttdeci">#define ARMNN_ASSERT(COND)</div><div class="ttdef"><b>Definition</b> <a href="_assert_8hpp_source.html#l00014">Assert.hpp:14</a></div></div>
<div class="ttc" id="a_assert_8hpp_html_a91c4dfde57907d7698c7531785690a7f"><div class="ttname"><a href="_assert_8hpp.html#a91c4dfde57907d7698c7531785690a7f">ARMNN_ASSERT_MSG</a></div><div class="ttdeci">#define ARMNN_ASSERT_MSG(COND, MSG)</div><div class="ttdef"><b>Definition</b> <a href="_assert_8hpp_source.html#l00015">Assert.hpp:15</a></div></div>
<div class="ttc" id="a_data_layout_indexed_8hpp_html"><div class="ttname"><a href="_data_layout_indexed_8hpp.html">DataLayoutIndexed.hpp</a></div></div>
<div class="ttc" id="a_optimization_8hpp_html"><div class="ttname"><a href="_optimization_8hpp.html">Optimization.hpp</a></div></div>
<div class="ttc" id="a_resolve_type_8hpp_html"><div class="ttname"><a href="_resolve_type_8hpp.html">ResolveType.hpp</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_base_tensor_html_a265f6f3ff9402ba2499541b8c2348e34"><div class="ttname"><a href="classarmnn_1_1_base_tensor.html#a265f6f3ff9402ba2499541b8c2348e34">armnn::BaseTensor::GetInfo</a></div><div class="ttdeci">const TensorInfo &amp; GetInfo() const</div><div class="ttdef"><b>Definition</b> <a href="_tensor_8hpp_source.html#l00297">Tensor.hpp:297</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_base_tensor_html_a8846406ac37fbd2204f0be16ee05d5b7"><div class="ttname"><a href="classarmnn_1_1_base_tensor.html#a8846406ac37fbd2204f0be16ee05d5b7">armnn::BaseTensor::GetNumElements</a></div><div class="ttdeci">unsigned int GetNumElements() const</div><div class="ttdef"><b>Definition</b> <a href="_tensor_8hpp_source.html#l00305">Tensor.hpp:305</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_base_tensor_html_aa81f67ac64f0c249e26499600c45d996"><div class="ttname"><a href="classarmnn_1_1_base_tensor.html#aa81f67ac64f0c249e26499600c45d996">armnn::BaseTensor::GetMemoryArea</a></div><div class="ttdeci">MemoryType GetMemoryArea() const</div><div class="ttdef"><b>Definition</b> <a href="_tensor_8hpp_source.html#l00307">Tensor.hpp:307</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_batch_normalization_layer_html"><div class="ttname"><a href="classarmnn_1_1_batch_normalization_layer.html">armnn::BatchNormalizationLayer</a></div><div class="ttdoc">This layer represents a batch normalization operation.</div><div class="ttdef"><b>Definition</b> <a href="_batch_normalization_layer_8hpp_source.html#l00015">BatchNormalizationLayer.hpp:16</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_const_tensor_html"><div class="ttname"><a href="classarmnn_1_1_const_tensor.html">armnn::ConstTensor</a></div><div class="ttdoc">A tensor defined by a TensorInfo (shape and data type) and an immutable backing store.</div><div class="ttdef"><b>Definition</b> <a href="_tensor_8hpp_source.html#l00329">Tensor.hpp:330</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_constant_layer_html"><div class="ttname"><a href="classarmnn_1_1_constant_layer.html">armnn::ConstantLayer</a></div><div class="ttdoc">A layer that the constant data can be bound to.</div><div class="ttdef"><b>Definition</b> <a href="_constant_layer_8hpp_source.html#l00015">ConstantLayer.hpp:16</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_constant_layer_html_ad0c4b8ee0efd8f9336571cbeab8a53fe"><div class="ttname"><a href="classarmnn_1_1_constant_layer.html#ad0c4b8ee0efd8f9336571cbeab8a53fe">armnn::ConstantLayer::m_LayerOutput</a></div><div class="ttdeci">std::shared_ptr&lt; ConstTensorHandle &gt; m_LayerOutput</div><div class="ttdef"><b>Definition</b> <a href="_constant_layer_8hpp_source.html#l00046">ConstantLayer.hpp:46</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_convolution2d_layer_html"><div class="ttname"><a href="classarmnn_1_1_convolution2d_layer.html">armnn::Convolution2dLayer</a></div><div class="ttdoc">This layer represents a convolution 2d operation.</div><div class="ttdef"><b>Definition</b> <a href="_convolution2d_layer_8hpp_source.html#l00015">Convolution2dLayer.hpp:16</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_depthwise_convolution2d_layer_html"><div class="ttname"><a href="classarmnn_1_1_depthwise_convolution2d_layer.html">armnn::DepthwiseConvolution2dLayer</a></div><div class="ttdoc">This layer represents a depthwise convolution 2d operation.</div><div class="ttdef"><b>Definition</b> <a href="_depthwise_convolution2d_layer_8hpp_source.html#l00015">DepthwiseConvolution2dLayer.hpp:16</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_graph_html"><div class="ttname"><a href="classarmnn_1_1_graph.html">armnn::Graph</a></div><div class="ttdef"><b>Definition</b> <a href="_graph_8hpp_source.html#l00030">Graph.hpp:31</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_graph_html_a3ff30c6669fdc69de1f5be1f89bacc3f"><div class="ttname"><a href="classarmnn_1_1_graph.html#a3ff30c6669fdc69de1f5be1f89bacc3f">armnn::Graph::InsertNewLayer</a></div><div class="ttdeci">LayerT * InsertNewLayer(InputSlot &amp;insertBefore, Args &amp;&amp;... args)</div><div class="ttdoc">Inserts a new layer between the output slot currently connected to insertBefore and insertBefore itse...</div><div class="ttdef"><b>Definition</b> <a href="_graph_8hpp_source.html#l00481">Graph.hpp:481</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_graph_html_a7563c5b899e7d0ada08fd0fdb202f205"><div class="ttname"><a href="classarmnn_1_1_graph.html#a7563c5b899e7d0ada08fd0fdb202f205">armnn::Graph::AddLayer</a></div><div class="ttdeci">LayerT * AddLayer(Args &amp;&amp;... args)</div><div class="ttdoc">Adds a new layer, of type LayerType, to the graph constructed with the arguments passed.</div><div class="ttdef"><b>Definition</b> <a href="_graph_8hpp_source.html#l00466">Graph.hpp:466</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_input_slot_html"><div class="ttname"><a href="classarmnn_1_1_input_slot.html">armnn::InputSlot</a></div><div class="ttdef"><b>Definition</b> <a href="_layer_8hpp_source.html#l00042">Layer.hpp:43</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_input_slot_html_a8cc88357e965a69501e0b2bdec768319"><div class="ttname"><a href="classarmnn_1_1_input_slot.html#a8cc88357e965a69501e0b2bdec768319">armnn::InputSlot::GetOwningLayer</a></div><div class="ttdeci">Layer &amp; GetOwningLayer() const</div><div class="ttdef"><b>Definition</b> <a href="_layer_8hpp_source.html#l00053">Layer.hpp:53</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_input_slot_html_a9ae1c86210bf4715afe24f9b2bcadf03"><div class="ttname"><a href="classarmnn_1_1_input_slot.html#a9ae1c86210bf4715afe24f9b2bcadf03">armnn::InputSlot::GetConnectedOutputSlot</a></div><div class="ttdeci">const OutputSlot * GetConnectedOutputSlot() const</div><div class="ttdef"><b>Definition</b> <a href="_layer_8hpp_source.html#l00056">Layer.hpp:56</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_layer_html"><div class="ttname"><a href="classarmnn_1_1_layer.html">armnn::Layer</a></div><div class="ttdef"><b>Definition</b> <a href="_layer_8hpp_source.html#l00230">Layer.hpp:231</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_layer_html_a247a09d09842358d1952cda6a3a165b5"><div class="ttname"><a href="classarmnn_1_1_layer.html#a247a09d09842358d1952cda6a3a165b5">armnn::Layer::GetInputSlot</a></div><div class="ttdeci">const InputSlot &amp; GetInputSlot(unsigned int index) const override</div><div class="ttdoc">Get a const input slot handle by slot index.</div><div class="ttdef"><b>Definition</b> <a href="_layer_8hpp_source.html#l00337">Layer.hpp:337</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_layer_html_a84d01c23dc71a5502a10c0f97f19ba1f"><div class="ttname"><a href="classarmnn_1_1_layer.html#a84d01c23dc71a5502a10c0f97f19ba1f">armnn::Layer::GetOutputSlot</a></div><div class="ttdeci">const OutputSlot &amp; GetOutputSlot(unsigned int index=0) const override</div><div class="ttdoc">Get the const output slot handle by slot index.</div><div class="ttdef"><b>Definition</b> <a href="_layer_8hpp_source.html#l00339">Layer.hpp:339</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_layer_html_ad47edad463024345ce1409153c259215"><div class="ttname"><a href="classarmnn_1_1_layer.html#ad47edad463024345ce1409153c259215">armnn::Layer::GetName</a></div><div class="ttdeci">const char * GetName() const override</div><div class="ttdoc">Returns the name of the layer.</div><div class="ttdef"><b>Definition</b> <a href="_layer_8hpp_source.html#l00332">Layer.hpp:332</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_layer_html_ad8e15c530c929ab823d89ae9fd2d3f11"><div class="ttname"><a href="classarmnn_1_1_layer.html#ad8e15c530c929ab823d89ae9fd2d3f11">armnn::Layer::GetType</a></div><div class="ttdeci">LayerType GetType() const override</div><div class="ttdoc">Returns the armnn::LayerType of this layer.</div><div class="ttdef"><b>Definition</b> <a href="_layer_8hpp_source.html#l00286">Layer.hpp:286</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_layer_html_aea909c7327109228ef618d459015def3"><div class="ttname"><a href="classarmnn_1_1_layer.html#aea909c7327109228ef618d459015def3">armnn::Layer::GetDataType</a></div><div class="ttdeci">DataType GetDataType() const</div><div class="ttdef"><b>Definition</b> <a href="_layer_8cpp_source.html#l00345">Layer.cpp:345</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_optimize_for_exclusive_connection_html"><div class="ttname"><a href="classarmnn_1_1_optimize_for_exclusive_connection.html">armnn::OptimizeForExclusiveConnection</a></div><div class="ttdef"><b>Definition</b> <a href="_optimization_8hpp_source.html#l00173">Optimization.hpp:175</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_output_slot_html"><div class="ttname"><a href="classarmnn_1_1_output_slot.html">armnn::OutputSlot</a></div><div class="ttdef"><b>Definition</b> <a href="_layer_8hpp_source.html#l00100">Layer.hpp:101</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_output_slot_html_a19d30f83e90f2612e6aec510715f790d"><div class="ttname"><a href="classarmnn_1_1_output_slot.html#a19d30f83e90f2612e6aec510715f790d">armnn::OutputSlot::MoveAllConnections</a></div><div class="ttdeci">void MoveAllConnections(OutputSlot &amp;destination)</div><div class="ttdoc">Moves all connections to another OutputSlot.</div><div class="ttdef"><b>Definition</b> <a href="_layer_8cpp_source.html#l00156">Layer.cpp:156</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_output_slot_html_a7e5c5771d741dd5473989047a9314728"><div class="ttname"><a href="classarmnn_1_1_output_slot.html#a7e5c5771d741dd5473989047a9314728">armnn::OutputSlot::SetTensorInfo</a></div><div class="ttdeci">void SetTensorInfo(const TensorInfo &amp;tensorInfo) override</div><div class="ttdef"><b>Definition</b> <a href="_layer_8cpp_source.html#l00095">Layer.cpp:95</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_output_slot_html_a8cc88357e965a69501e0b2bdec768319"><div class="ttname"><a href="classarmnn_1_1_output_slot.html#a8cc88357e965a69501e0b2bdec768319">armnn::OutputSlot::GetOwningLayer</a></div><div class="ttdeci">Layer &amp; GetOwningLayer() const</div><div class="ttdef"><b>Definition</b> <a href="_layer_8hpp_source.html#l00132">Layer.hpp:132</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_output_slot_html_ac72a192dfcfa19e6ce826f99b415a11d"><div class="ttname"><a href="classarmnn_1_1_output_slot.html#ac72a192dfcfa19e6ce826f99b415a11d">armnn::OutputSlot::Disconnect</a></div><div class="ttdeci">void Disconnect(InputSlot &amp;slot)</div><div class="ttdef"><b>Definition</b> <a href="_layer_8cpp_source.html#l00131">Layer.cpp:131</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_output_slot_html_ada2ad7d1caeeb4ef6195c8925fad6a65"><div class="ttname"><a href="classarmnn_1_1_output_slot.html#ada2ad7d1caeeb4ef6195c8925fad6a65">armnn::OutputSlot::GetTensorInfo</a></div><div class="ttdeci">const TensorInfo &amp; GetTensorInfo() const override</div><div class="ttdef"><b>Definition</b> <a href="_layer_8cpp_source.html#l00100">Layer.cpp:100</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_output_slot_html_adcfb97035799ea4c043f9ef370714815"><div class="ttname"><a href="classarmnn_1_1_output_slot.html#adcfb97035799ea4c043f9ef370714815">armnn::OutputSlot::Connect</a></div><div class="ttdeci">int Connect(InputSlot &amp;destination)</div><div class="ttdef"><b>Definition</b> <a href="_layer_8cpp_source.html#l00123">Layer.cpp:123</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_tensor_info_html"><div class="ttname"><a href="classarmnn_1_1_tensor_info.html">armnn::TensorInfo</a></div><div class="ttdef"><b>Definition</b> <a href="_tensor_8hpp_source.html#l00152">Tensor.hpp:153</a></div></div>
<div class="ttc" id="aclassarmnn_1_1_tensor_info_html_a0b28207ca7de967c2da4113bdec9518f"><div class="ttname"><a href="classarmnn_1_1_tensor_info.html#a0b28207ca7de967c2da4113bdec9518f">armnn::TensorInfo::GetShape</a></div><div class="ttdeci">const TensorShape &amp; GetShape() const</div><div class="ttdef"><b>Definition</b> <a href="_tensor_8hpp_source.html#l00193">Tensor.hpp:193</a></div></div>
<div class="ttc" id="aclassarmnn_1_1optimizations_1_1_fuse_batch_norm_html"><div class="ttname"><a href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.html">armnn::optimizations::FuseBatchNorm</a></div><div class="ttdef"><b>Definition</b> <a href="#l00019">FuseBatchNorm.hpp:20</a></div></div>
<div class="ttc" id="aclassarmnn_1_1optimizations_1_1_fuse_batch_norm_html_a0ff9a790927b898d90261a8ea0e479e6"><div class="ttname"><a href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.html#a0ff9a790927b898d90261a8ea0e479e6">armnn::optimizations::FuseBatchNorm::~FuseBatchNorm</a></div><div class="ttdeci">~FuseBatchNorm()=default</div></div>
<div class="ttc" id="aclassarmnn_1_1optimizations_1_1_fuse_batch_norm_html_a5a8476ffc04ce7460bb09ad50d1d23de"><div class="ttname"><a href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.html#a5a8476ffc04ce7460bb09ad50d1d23de">armnn::optimizations::FuseBatchNorm::Run</a></div><div class="ttdeci">void Run(Graph &amp;graph, InputSlot &amp;connection) const</div><div class="ttdoc">Run for every exclusive connection between any base Convolution layer and a child BatchNorm layer for...</div><div class="ttdef"><b>Definition</b> <a href="#l00027">FuseBatchNorm.hpp:27</a></div></div>
<div class="ttc" id="aclassarmnn_1_1optimizations_1_1_fuse_batch_norm_html_abe49327783cb8bdc12c085c987db14db"><div class="ttname"><a href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.html#abe49327783cb8bdc12c085c987db14db">armnn::optimizations::FuseBatchNorm::FuseBatchNorm</a></div><div class="ttdeci">FuseBatchNorm()=default</div></div>
<div class="ttc" id="aclassarmnn_utils_1_1_data_layout_indexed_html"><div class="ttname"><a href="classarmnn_utils_1_1_data_layout_indexed.html">armnnUtils::DataLayoutIndexed</a></div><div class="ttdoc">Provides access to the appropriate indexes for Channels, Height and Width based on DataLayout.</div><div class="ttdef"><b>Definition</b> <a href="_data_layout_indexed_8hpp_source.html#l00017">DataLayoutIndexed.hpp:18</a></div></div>
<div class="ttc" id="aclassarmnn_utils_1_1_data_layout_indexed_html_a414e6f95548e6f7a01d5028b55ad3941"><div class="ttname"><a href="classarmnn_utils_1_1_data_layout_indexed.html#a414e6f95548e6f7a01d5028b55ad3941">armnnUtils::DataLayoutIndexed::GetWidthIndex</a></div><div class="ttdeci">unsigned int GetWidthIndex() const</div><div class="ttdef"><b>Definition</b> <a href="_data_layout_indexed_8hpp_source.html#l00025">DataLayoutIndexed.hpp:25</a></div></div>
<div class="ttc" id="aclassarmnn_utils_1_1_data_layout_indexed_html_a61c00316c443adc233c24e85c6c5b740"><div class="ttname"><a href="classarmnn_utils_1_1_data_layout_indexed.html#a61c00316c443adc233c24e85c6c5b740">armnnUtils::DataLayoutIndexed::GetHeightIndex</a></div><div class="ttdeci">unsigned int GetHeightIndex() const</div><div class="ttdef"><b>Definition</b> <a href="_data_layout_indexed_8hpp_source.html#l00024">DataLayoutIndexed.hpp:24</a></div></div>
<div class="ttc" id="aclassarmnn_utils_1_1_data_layout_indexed_html_a861b2621ee46e4b63379988b360b8cd9"><div class="ttname"><a href="classarmnn_utils_1_1_data_layout_indexed.html#a861b2621ee46e4b63379988b360b8cd9">armnnUtils::DataLayoutIndexed::GetChannelsIndex</a></div><div class="ttdeci">unsigned int GetChannelsIndex() const</div><div class="ttdef"><b>Definition</b> <a href="_data_layout_indexed_8hpp_source.html#l00023">DataLayoutIndexed.hpp:23</a></div></div>
<div class="ttc" id="anamespacearmnn_1_1optimizations_html"><div class="ttname"><a href="namespacearmnn_1_1optimizations.html">armnn::optimizations</a></div><div class="ttdef"><b>Definition</b> <a href="_add_broadcast_reshape_layer_8hpp_source.html#l00014">AddBroadcastReshapeLayer.hpp:15</a></div></div>
<div class="ttc" id="anamespacearmnn_1_1optimizations_html_a51e4143e66bc9ba9636fb6880a18a3b3"><div class="ttname"><a href="namespacearmnn_1_1optimizations.html#a51e4143e66bc9ba9636fb6880a18a3b3">armnn::optimizations::FuseBatchNormIntoConvolution2DFloat16</a></div><div class="ttdeci">OptimizeForExclusiveConnection&lt; Convolution2dLayer, BatchNormalizationLayer, FuseBatchNorm&lt; Convolution2dLayer, armnn::DataType::Float16 &gt; &gt; FuseBatchNormIntoConvolution2DFloat16</div><div class="ttdef"><b>Definition</b> <a href="#l00224">FuseBatchNorm.hpp:224</a></div></div>
<div class="ttc" id="anamespacearmnn_1_1optimizations_html_ab2d7602801c93779f038cda5e4850502"><div class="ttname"><a href="namespacearmnn_1_1optimizations.html#ab2d7602801c93779f038cda5e4850502">armnn::optimizations::FuseBatchNormIntoDepthwiseConvolution2DFloat16</a></div><div class="ttdeci">OptimizeForExclusiveConnection&lt; DepthwiseConvolution2dLayer, BatchNormalizationLayer, FuseBatchNorm&lt; DepthwiseConvolution2dLayer, armnn::DataType::Float16 &gt; &gt; FuseBatchNormIntoDepthwiseConvolution2DFloat16</div><div class="ttdef"><b>Definition</b> <a href="#l00234">FuseBatchNorm.hpp:234</a></div></div>
<div class="ttc" id="anamespacearmnn_1_1optimizations_html_aba46a6261e0026b6a35e85fed91f1e35"><div class="ttname"><a href="namespacearmnn_1_1optimizations.html#aba46a6261e0026b6a35e85fed91f1e35">armnn::optimizations::FuseBatchNormIntoDepthwiseConvolution2DFloat32</a></div><div class="ttdeci">OptimizeForExclusiveConnection&lt; DepthwiseConvolution2dLayer, BatchNormalizationLayer, FuseBatchNorm&lt; DepthwiseConvolution2dLayer, armnn::DataType::Float32 &gt; &gt; FuseBatchNormIntoDepthwiseConvolution2DFloat32</div><div class="ttdef"><b>Definition</b> <a href="#l00229">FuseBatchNorm.hpp:229</a></div></div>
<div class="ttc" id="anamespacearmnn_1_1optimizations_html_adbe678295995f56256c7c2d40c6e3e5d"><div class="ttname"><a href="namespacearmnn_1_1optimizations.html#adbe678295995f56256c7c2d40c6e3e5d">armnn::optimizations::FuseBatchNormIntoConvolution2DFloat32</a></div><div class="ttdeci">OptimizeForExclusiveConnection&lt; Convolution2dLayer, BatchNormalizationLayer, FuseBatchNorm&lt; Convolution2dLayer, armnn::DataType::Float32 &gt; &gt; FuseBatchNormIntoConvolution2DFloat32</div><div class="ttdef"><b>Definition</b> <a href="#l00219">FuseBatchNorm.hpp:219</a></div></div>
<div class="ttc" id="anamespacearmnn_html"><div class="ttname"><a href="namespacearmnn.html">armnn</a></div><div class="ttdoc">Copyright (c) 2021 ARM Limited and Contributors.</div><div class="ttdef"><b>Definition</b> <a href="01__00__quick__start_8dox_source.html#l00006">01_00_quick_start.dox:7</a></div></div>
<div class="ttc" id="anamespacearmnn_html_a0743ed5e860c316a20b68ca96301b411"><div class="ttname"><a href="namespacearmnn.html#a0743ed5e860c316a20b68ca96301b411">armnn::ResolveType</a></div><div class="ttdeci">typename ResolveTypeImpl&lt; DT &gt;::Type ResolveType</div><div class="ttdef"><b>Definition</b> <a href="_resolve_type_8hpp_source.html#l00079">ResolveType.hpp:79</a></div></div>
<div class="ttc" id="anamespacearmnn_html_a56943a0946e5f15e5e58054b8e7a04a4adb033d2f81b68f9a17e8f62de69fed4a"><div class="ttname"><a href="namespacearmnn.html#a56943a0946e5f15e5e58054b8e7a04a4adb033d2f81b68f9a17e8f62de69fed4a">armnn::LayerType::Convolution2d</a></div><div class="ttdeci">@ Convolution2d</div><div class="ttdef"><b>Definition</b> <a href="_types_8hpp_source.html#l00496">Types.hpp:496</a></div></div>
<div class="ttc" id="anamespacearmnn_html_a56943a0946e5f15e5e58054b8e7a04a4ae4743c3ec15d1d84169b17264634692e"><div class="ttname"><a href="namespacearmnn.html#a56943a0946e5f15e5e58054b8e7a04a4ae4743c3ec15d1d84169b17264634692e">armnn::LayerType::BatchNormalization</a></div><div class="ttdeci">@ BatchNormalization</div><div class="ttdef"><b>Definition</b> <a href="_types_8hpp_source.html#l00496">Types.hpp:496</a></div></div>
<div class="ttc" id="anamespacearmnn_html_a56943a0946e5f15e5e58054b8e7a04a4af97adbfc88b7012a0243215b1076e7e7"><div class="ttname"><a href="namespacearmnn.html#a56943a0946e5f15e5e58054b8e7a04a4af97adbfc88b7012a0243215b1076e7e7">armnn::LayerType::DepthwiseConvolution2d</a></div><div class="ttdeci">@ DepthwiseConvolution2d</div><div class="ttdef"><b>Definition</b> <a href="_types_8hpp_source.html#l00496">Types.hpp:496</a></div></div>
<div class="ttc" id="anamespacearmnn_html_aa61aa94683e990075a26c5e56ddc85eb"><div class="ttname"><a href="namespacearmnn.html#aa61aa94683e990075a26c5e56ddc85eb">armnn::PolymorphicDowncast</a></div><div class="ttdeci">DestType PolymorphicDowncast(SourceType *value)</div><div class="ttdoc">Polymorphic downcast for build in pointers only.</div><div class="ttdef"><b>Definition</b> <a href="_polymorphic_downcast_8hpp_source.html#l00074">PolymorphicDowncast.hpp:74</a></div></div>
<div class="ttc" id="anamespacearmnn_html_ad1d5cce2d9e9a5d61c243e5c989112e0ad066db54b89b0912e7e7c6da51e2da51"><div class="ttname"><a href="namespacearmnn.html#ad1d5cce2d9e9a5d61c243e5c989112e0ad066db54b89b0912e7e7c6da51e2da51">armnn::DataLayout::NHWC</a></div><div class="ttdeci">@ NHWC</div><div class="ttdef"><b>Definition</b> <a href="_types_8hpp_source.html#l00065">Types.hpp:65</a></div></div>
<div class="ttc" id="anamespacearmnn_html_ad8ed01ff3ff33333d8e19db4d2818bb6"><div class="ttname"><a href="namespacearmnn.html#ad8ed01ff3ff33333d8e19db4d2818bb6">armnn::DataType</a></div><div class="ttdeci">DataType</div><div class="ttdef"><b>Definition</b> <a href="_types_8hpp_source.html#l00048">Types.hpp:49</a></div></div>
<div class="ttc" id="anamespacearmnn_html_aff5e3bc27829d0cdb153a80dce50fa34"><div class="ttname"><a href="namespacearmnn.html#aff5e3bc27829d0cdb153a80dce50fa34">armnn::IgnoreUnused</a></div><div class="ttdeci">void IgnoreUnused(Ts &amp;&amp;...)</div><div class="ttdef"><b>Definition</b> <a href="_ignore_unused_8hpp_source.html#l00014">IgnoreUnused.hpp:14</a></div></div>
<div class="ttc" id="astructarmnn_1_1_batch_normalization_descriptor_html"><div class="ttname"><a href="structarmnn_1_1_batch_normalization_descriptor.html">armnn::BatchNormalizationDescriptor</a></div><div class="ttdoc">A BatchNormalizationDescriptor for the BatchNormalizationLayer.</div><div class="ttdef"><b>Definition</b> <a href="_descriptors_8hpp_source.html#l00828">Descriptors.hpp:829</a></div></div>
<div class="ttc" id="astructarmnn_1_1_batch_normalization_descriptor_html_a11c821c7524251004a72ed13c510853c"><div class="ttname"><a href="structarmnn_1_1_batch_normalization_descriptor.html#a11c821c7524251004a72ed13c510853c">armnn::BatchNormalizationDescriptor::m_Eps</a></div><div class="ttdeci">float m_Eps</div><div class="ttdoc">Value to add to the variance. Used to avoid dividing by zero.</div><div class="ttdef"><b>Definition</b> <a href="_descriptors_8hpp_source.html#l00841">Descriptors.hpp:841</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
</div><!-- container -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a href="dir_68267d1309a1af8e8297ef4c3efbcdba.html">src</a></li><li class="navelem"><a href="dir_e0a84d05c80a2ef4231141dcbbeac5c8.html">armnn</a></li><li class="navelem"><a href="dir_5bee762cfd03f62aa80233ed05f1bfdf.html">optimizations</a></li><li class="navelem"><a href="_fuse_batch_norm_8hpp.html">FuseBatchNorm.hpp</a></li>
    <li class="footer">Generated on <span class="timestamp"></span> for Arm NN by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.14.0 </li>
  </ul>
</div>
</body>
</html>
