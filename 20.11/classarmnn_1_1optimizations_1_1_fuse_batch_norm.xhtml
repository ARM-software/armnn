<!-- Copyright (c) 2020 ARM Limited. -->
<!--                                 -->
<!-- SPDX-License-Identifier: MIT    -->
<!--                                 -->
<!-- HTML header for doxygen 1.8.13-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="robots" content="NOINDEX, NOFOLLOW" />
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ArmNN: FuseBatchNorm&lt; ConvLayer, ArmnnType, T &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <img alt="ArmNN" src="Arm_NN_horizontal_blue.png" style="max-width: 10rem; margin-top: .5rem; margin-left 10px"/>
  <td style="padding-left: 0.5em;">
   <div id="projectname">
   &#160;<span id="projectnumber">20.11</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('classarmnn_1_1optimizations_1_1_fuse_batch_norm.xhtml','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-methods">Protected Member Functions</a> &#124;
<a href="classarmnn_1_1optimizations_1_1_fuse_batch_norm-members.xhtml">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">FuseBatchNorm&lt; ConvLayer, ArmnnType, T &gt; Class Template Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p><code>#include &lt;<a class="el" href="_fuse_batch_norm_8hpp_source.xhtml">FuseBatchNorm.hpp</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a5a8476ffc04ce7460bb09ad50d1d23de"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.xhtml#a5a8476ffc04ce7460bb09ad50d1d23de">Run</a> (<a class="el" href="classarmnn_1_1_graph.xhtml">Graph</a> &amp;graph, <a class="el" href="classarmnn_1_1_input_slot.xhtml">InputSlot</a> &amp;connection) const</td></tr>
<tr class="memdesc:a5a8476ffc04ce7460bb09ad50d1d23de"><td class="mdescLeft">&#160;</td><td class="mdescRight">Run for every exclusive connection between any base Convolution layer and a child BatchNorm layer for not quantized layers.  <a href="#a5a8476ffc04ce7460bb09ad50d1d23de">More...</a><br /></td></tr>
<tr class="separator:a5a8476ffc04ce7460bb09ad50d1d23de"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-methods"></a>
Protected Member Functions</h2></td></tr>
<tr class="memitem:abe49327783cb8bdc12c085c987db14db"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.xhtml#abe49327783cb8bdc12c085c987db14db">FuseBatchNorm</a> ()=default</td></tr>
<tr class="separator:abe49327783cb8bdc12c085c987db14db"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0ff9a790927b898d90261a8ea0e479e6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.xhtml#a0ff9a790927b898d90261a8ea0e479e6">~FuseBatchNorm</a> ()=default</td></tr>
<tr class="separator:a0ff9a790927b898d90261a8ea0e479e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><h3>template&lt;typename ConvLayer, armnn::DataType ArmnnType, typename T = armnn::ResolveType&lt;ArmnnType&gt;&gt;<br />
class armnn::optimizations::FuseBatchNorm&lt; ConvLayer, ArmnnType, T &gt;</h3>


<p class="definition">Definition at line <a class="el" href="_fuse_batch_norm_8hpp_source.xhtml#l00019">19</a> of file <a class="el" href="_fuse_batch_norm_8hpp_source.xhtml">FuseBatchNorm.hpp</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="abe49327783cb8bdc12c085c987db14db"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abe49327783cb8bdc12c085c987db14db">&#9670;&nbsp;</a></span>FuseBatchNorm()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.xhtml">FuseBatchNorm</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">default</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="reference">Referenced by <a class="el" href="_fuse_batch_norm_8hpp_source.xhtml#l00027">FuseBatchNorm&lt; ConvLayer, ArmnnType, T &gt;::Run()</a>.</p>

</div>
</div>
<a id="a0ff9a790927b898d90261a8ea0e479e6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0ff9a790927b898d90261a8ea0e479e6">&#9670;&nbsp;</a></span>~FuseBatchNorm()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">~<a class="el" href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.xhtml">FuseBatchNorm</a> </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">default</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="reference">Referenced by <a class="el" href="_fuse_batch_norm_8hpp_source.xhtml#l00027">FuseBatchNorm&lt; ConvLayer, ArmnnType, T &gt;::Run()</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a5a8476ffc04ce7460bb09ad50d1d23de"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5a8476ffc04ce7460bb09ad50d1d23de">&#9670;&nbsp;</a></span>Run()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void Run </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classarmnn_1_1_graph.xhtml">Graph</a> &amp;&#160;</td>
          <td class="paramname"><em>graph</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classarmnn_1_1_input_slot.xhtml">InputSlot</a> &amp;&#160;</td>
          <td class="paramname"><em>connection</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Run for every exclusive connection between any base Convolution layer and a child BatchNorm layer for not quantized layers. </p>
<p>The child will be removed, the base will be removed if it's left unconnected. A new Convolution layer will be added, its weights and bias will be calculated using the weights and bias of the base Convolution layer combined with the parameters of the child BatchNorm layer. </p>

<p class="definition">Definition at line <a class="el" href="_fuse_batch_norm_8hpp_source.xhtml#l00027">27</a> of file <a class="el" href="_fuse_batch_norm_8hpp_source.xhtml">FuseBatchNorm.hpp</a>.</p>

<p class="reference">References <a class="el" href="_assert_8hpp_source.xhtml#l00014">ARMNN_ASSERT</a>, <a class="el" href="_assert_8hpp_source.xhtml#l00015">ARMNN_ASSERT_MSG</a>, <a class="el" href="namespacearmnn.xhtml#a56943a0946e5f15e5e58054b8e7a04a4ae4743c3ec15d1d84169b17264634692e">armnn::BatchNormalization</a>, <a class="el" href="namespacearmnn.xhtml#a56943a0946e5f15e5e58054b8e7a04a4adb033d2f81b68f9a17e8f62de69fed4a">armnn::Convolution2d</a>, <a class="el" href="namespacearmnn.xhtml#a56943a0946e5f15e5e58054b8e7a04a4af97adbfc88b7012a0243215b1076e7e7">armnn::DepthwiseConvolution2d</a>, <a class="el" href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.xhtml#abe49327783cb8bdc12c085c987db14db">FuseBatchNorm&lt; ConvLayer, ArmnnType, T &gt;::FuseBatchNorm()</a>, <a class="el" href="_layer_8hpp_source.xhtml#l00055">InputSlot::GetConnectedOutputSlot()</a>, <a class="el" href="_layer_8cpp_source.xhtml#l00283">Layer::GetDataType()</a>, <a class="el" href="_layer_8hpp_source.xhtml#l00313">Layer::GetInputSlot()</a>, <a class="el" href="_layer_8hpp_source.xhtml#l00308">Layer::GetName()</a>, <a class="el" href="_layer_8hpp_source.xhtml#l00315">Layer::GetOutputSlot()</a>, <a class="el" href="_layer_8hpp_source.xhtml#l00052">InputSlot::GetOwningLayer()</a>, <a class="el" href="_layer_8hpp_source.xhtml#l00115">OutputSlot::GetOwningLayer()</a>, <a class="el" href="_layer_8hpp_source.xhtml#l00262">Layer::GetType()</a>, <a class="el" href="_ignore_unused_8hpp_source.xhtml#l00014">armnn::IgnoreUnused()</a>, <a class="el" href="_graph_8hpp_source.xhtml#l00416">Graph::InsertNewLayer()</a>, <a class="el" href="_descriptors_8hpp_source.xhtml#l00634">BatchNormalizationDescriptor::m_Eps</a>, <a class="el" href="_layer_8cpp_source.xhtml#l00116">OutputSlot::MoveAllConnections()</a>, <a class="el" href="namespacearmnn.xhtml#ad1d5cce2d9e9a5d61c243e5c989112e0ad066db54b89b0912e7e7c6da51e2da51">armnn::NHWC</a>, and <a class="el" href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.xhtml#a0ff9a790927b898d90261a8ea0e479e6">FuseBatchNorm&lt; ConvLayer, ArmnnType, T &gt;::~FuseBatchNorm()</a>.</p>
<div class="fragment"><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;    {</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;        Layer&amp; base  = connection.GetConnectedOutputSlot()-&gt;GetOwningLayer();</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;        Layer&amp; child = connection.GetOwningLayer();</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;        <span class="keywordtype">bool</span> depthwise = (base.GetType() == <a class="code" href="namespacearmnn.xhtml#a56943a0946e5f15e5e58054b8e7a04a4af97adbfc88b7012a0243215b1076e7e7">LayerType::DepthwiseConvolution2d</a>);</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;        <a class="code" href="_assert_8hpp.xhtml#a5698be69cbd5dfe6c28fcd9867e8cbed">ARMNN_ASSERT</a>(base.GetType() == <a class="code" href="namespacearmnn.xhtml#a56943a0946e5f15e5e58054b8e7a04a4adb033d2f81b68f9a17e8f62de69fed4a">LayerType::Convolution2d</a> || depthwise);</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;        <a class="code" href="_assert_8hpp.xhtml#a5698be69cbd5dfe6c28fcd9867e8cbed">ARMNN_ASSERT</a>(child.GetType() == <a class="code" href="namespacearmnn.xhtml#a56943a0946e5f15e5e58054b8e7a04a4ae4743c3ec15d1d84169b17264634692e">LayerType::BatchNormalization</a>);</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;        <span class="keywordflow">if</span> (base.GetDataType() == ArmnnType &amp;&amp; child.GetDataType() == ArmnnType)</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;        {</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;            OutputSlot* parentOut = base.GetInputSlot(0).GetConnectedOutputSlot();</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;            <span class="keyword">auto</span> convLayer      = PolymorphicDowncast&lt;ConvLayer*&gt;(&amp;base);</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;            <span class="keyword">auto</span> batchNormLayer = PolymorphicDowncast&lt;BatchNormalizationLayer*&gt;(&amp;child);</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;            <span class="comment">// Read convolution and batch norm parameters</span></div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;            BatchNormalizationDescriptor batchNormDescriptor = batchNormLayer-&gt;GetParameters();</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;            <span class="keyword">auto</span> epsilon = batchNormDescriptor.m_Eps;</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;            <a class="code" href="namespacearmnn.xhtml#a44affeeb090c3c6a3062830562672e84">IgnoreUnused</a>(epsilon);</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;            ConstTensor betaTensor(batchNormLayer-&gt;m_Beta-&gt;GetTensorInfo(), batchNormLayer-&gt;m_Beta-&gt;Map(<span class="keyword">true</span>));</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;            ConstTensor gammaTensor(batchNormLayer-&gt;m_Gamma-&gt;GetTensorInfo(), batchNormLayer-&gt;m_Gamma-&gt;Map(<span class="keyword">true</span>));</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;            ConstTensor meanTensor(batchNormLayer-&gt;m_Mean-&gt;GetTensorInfo(), batchNormLayer-&gt;m_Mean-&gt;Map(<span class="keyword">true</span>));</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;            ConstTensor varTensor(batchNormLayer-&gt;m_Variance-&gt;GetTensorInfo(), batchNormLayer-&gt;m_Variance-&gt;Map(<span class="keyword">true</span>));</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;            <span class="keyword">auto</span> convDescriptor = convLayer-&gt;GetParameters();</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;            <span class="keyword">auto</span> weightsInfo(convLayer-&gt;m_Weight-&gt;GetTensorInfo());</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;            ConstTensor weightsTensor(weightsInfo, convLayer-&gt;m_Weight-&gt;Map(<span class="keyword">true</span>));</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;            <a class="code" href="classarmnn_utils_1_1_data_layout_indexed.xhtml">armnnUtils::DataLayoutIndexed</a> dataLayout(convDescriptor.m_DataLayout);</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;            <span class="keyword">auto</span> weightsShape = weightsInfo.GetShape();</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;            <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> depthMultiplier = depthwise ? weightsShape[0] : 1;</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;            <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> inputChannels   = depthwise ? weightsShape[1] :</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;                                                             weightsShape[dataLayout.GetChannelsIndex()];</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;            <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> outputChannels  = depthwise ? inputChannels * depthMultiplier : weightsShape[0];</div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;            <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> weightsHeight   = depthwise ? weightsShape[2] :</div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;                                                             weightsShape[dataLayout.GetHeightIndex()];</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;            <span class="keyword">const</span> <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> weightsWidth    = depthwise ? weightsShape[3] :</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;                                                             weightsShape[dataLayout.GetWidthIndex()];</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;            <span class="keyword">const</span> <span class="keyword">auto</span>* weightsBuffer = <span class="keyword">static_cast&lt;</span><span class="keyword">const </span>T*<span class="keyword">&gt;</span>(weightsTensor.GetMemoryArea());</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;            <span class="keyword">const</span> <span class="keyword">auto</span>* betaBuffer    = <span class="keyword">static_cast&lt;</span><span class="keyword">const </span>T*<span class="keyword">&gt;</span>(betaTensor.GetMemoryArea());</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;            <span class="keyword">const</span> <span class="keyword">auto</span>* gammaBuffer   = <span class="keyword">static_cast&lt;</span><span class="keyword">const </span>T*<span class="keyword">&gt;</span>(gammaTensor.GetMemoryArea());</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;            <span class="keyword">const</span> <span class="keyword">auto</span>* meanBuffer    = <span class="keyword">static_cast&lt;</span><span class="keyword">const </span>T*<span class="keyword">&gt;</span>(meanTensor.GetMemoryArea());</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;            <span class="keyword">const</span> <span class="keyword">auto</span>* varBuffer     = <span class="keyword">static_cast&lt;</span><span class="keyword">const </span>T*<span class="keyword">&gt;</span>(varTensor.GetMemoryArea());</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;            std::vector&lt;T&gt; weightsVector (weightsBuffer, weightsBuffer + weightsTensor.GetNumElements());</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;            std::vector&lt;T&gt; betaVector    (betaBuffer, betaBuffer + betaTensor.GetNumElements());</div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;            std::vector&lt;T&gt; gammaVector   (gammaBuffer, gammaBuffer + gammaTensor.GetNumElements());</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;            std::vector&lt;T&gt; meanVector    (meanBuffer, meanBuffer + meanTensor.GetNumElements());</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;            std::vector&lt;T&gt; varianceVector(varBuffer, varBuffer + varTensor.GetNumElements());</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;            <span class="comment">// fusedWeights = ( gamma * weights ) / ( std - epsilon);</span></div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;            std::vector&lt;T&gt; fusedWeightsVector(weightsVector.size());</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;            <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> depthwiseMultiplierIdx = 0;</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> cInput = 0; cInput &lt; inputChannels; ++cInput)</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;            {</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;                <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> cOut = 0; cOut &lt; outputChannels; ++cOut)</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;                {</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;                    T mult = gammaVector[cOut] / <span class="keyword">static_cast&lt;</span>T<span class="keyword">&gt;</span>(sqrtf (varianceVector[cOut] + epsilon));</div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;                    <span class="keywordflow">if</span> (depthwise)</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;                    {</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;                        cInput = cOut / depthMultiplier;</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;                        depthwiseMultiplierIdx = cOut % depthMultiplier;</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;                    }</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;                    <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> h = 0; h &lt; weightsHeight; ++h)</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;                    {</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;                        <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> w = 0; w &lt; weightsWidth; ++w)</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;                        {</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;                            <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> weightsIdx = 0;</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;                            <span class="keywordflow">if</span> (depthwise)</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;                            {</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;                                weightsIdx = depthwiseMultiplierIdx * weightsWidth * weightsHeight * inputChannels +</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;                                             cInput * weightsWidth * weightsHeight +</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;                                             h * weightsWidth +</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;                                             w;</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;                            }</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;                            <span class="keywordflow">else</span> <span class="keywordflow">if</span> (convDescriptor.m_DataLayout == <a class="code" href="namespacearmnn.xhtml#ad1d5cce2d9e9a5d61c243e5c989112e0ad066db54b89b0912e7e7c6da51e2da51">DataLayout::NHWC</a>)</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;                            {</div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;                                weightsIdx = cOut * weightsHeight * weightsWidth * inputChannels +</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;                                             h * weightsWidth * inputChannels +</div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;                                             w * inputChannels +</div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;                                             cInput;</div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;                            }</div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;                            <span class="keywordflow">else</span></div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;                            {</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;                                weightsIdx = cOut * weightsWidth * weightsHeight * inputChannels +</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;                                             cInput * weightsWidth * weightsHeight +</div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;                                             h * weightsWidth +</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;                                             w;</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;                            }</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;                            fusedWeightsVector[weightsIdx] = mult * weightsVector[weightsIdx];</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;                        }</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;                    }</div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;                }</div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;            }</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;            ConstTensor fusedWeightsTensor(weightsInfo, fusedWeightsVector);</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;            <span class="comment">//  fusedBias = (gamma * (bias - mean)) / (variance - epsilon) + beta;</span></div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;            std::vector&lt;T&gt; fusedBiasVector(outputChannels);</div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;            <span class="keywordflow">if</span> (convDescriptor.m_BiasEnabled)</div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;            {</div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;                <a class="code" href="_assert_8hpp.xhtml#a91c4dfde57907d7698c7531785690a7f">ARMNN_ASSERT_MSG</a>(convLayer-&gt;m_Bias != <span class="keyword">nullptr</span>,</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;                                 <span class="stringliteral">&quot;FuseBatchNorm: Bias data should not be null if bias is enabled.&quot;</span>);</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;                ConstTensor biasTensor(convLayer-&gt;m_Bias-&gt;GetTensorInfo(), convLayer-&gt;m_Bias-&gt;Map(<span class="keyword">true</span>));</div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;                <span class="keyword">const</span> <span class="keyword">auto</span>* biasBuffer = <span class="keyword">static_cast&lt;</span><span class="keyword">const </span>T*<span class="keyword">&gt;</span>(biasTensor.GetMemoryArea());</div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;                std::vector&lt;T&gt; biasVector(biasBuffer, biasBuffer + biasTensor.GetNumElements());</div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;</div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;                <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> cOut = 0; cOut &lt; outputChannels; ++cOut)</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;                {</div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;                    fusedBiasVector[cOut] = ((gammaVector[cOut] * (biasVector[cOut] - meanVector[cOut])) /</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;                                             sqrtf(varianceVector[cOut] + epsilon)) + betaVector[cOut];</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;                }</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;            }</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;            <span class="keywordflow">else</span></div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;            {</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;                convDescriptor.m_BiasEnabled = <span class="keyword">true</span>;</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;                std::vector&lt;T&gt; biasVector(outputChannels, T(0));</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;                <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> cOut = 0; cOut &lt; outputChannels; ++cOut)</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;                {</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;                    fusedBiasVector[cOut] = ((gammaVector[cOut] * (biasVector[cOut] - meanVector[cOut])) /</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;                                             sqrtf(varianceVector[cOut] + epsilon)) + betaVector[cOut];</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;                }</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;            }</div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;            ConstTensor fusedBiasTensor(TensorInfo({outputChannels}, ArmnnType), fusedBiasVector);</div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;            <span class="comment">// Insert the new convolution layer that has batch norm parameters fused into</span></div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;            <span class="keyword">const</span> std::string name = std::string(<span class="stringliteral">&quot;fused-&quot;</span>) + child.GetName() + std::string(<span class="stringliteral">&quot;-into-&quot;</span>) + base.GetName();</div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;            <span class="keyword">auto</span>&amp; newConv2dLayer = *graph.InsertNewLayer&lt;ConvLayer&gt;(base.GetInputSlot(0),</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;                                                                    convDescriptor,</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;                                                                    name.c_str());</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;            newConv2dLayer.m_Weight = std::make_unique&lt;ScopedCpuTensorHandle&gt;(fusedWeightsTensor);</div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;            newConv2dLayer.m_Bias = std::make_unique&lt;ScopedCpuTensorHandle&gt;(ConstTensor(fusedBiasTensor));</div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;            <span class="comment">// Reconnects with original parent.</span></div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;            newConv2dLayer.GetOutputSlot().MoveAllConnections(*parentOut);</div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;            <span class="comment">// Parent is now the new convolution2d layer.</span></div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;            parentOut = &amp;newConv2dLayer.GetOutputSlot();</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;            <span class="comment">// Moves connections in child output to parent layer.</span></div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;            <span class="comment">// Child layer will be removed as it&#39;s left unconnected.</span></div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;            <span class="comment">// Base layer will be removed if left unconnected.</span></div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;            child.GetOutputSlot().MoveAllConnections(*parentOut);</div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;        }</div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;    }</div><div class="ttc" id="namespacearmnn_xhtml_a44affeeb090c3c6a3062830562672e84"><div class="ttname"><a href="namespacearmnn.xhtml#a44affeeb090c3c6a3062830562672e84">armnn::IgnoreUnused</a></div><div class="ttdeci">void IgnoreUnused(Ts &amp;&amp;...)</div><div class="ttdef"><b>Definition:</b> <a href="_ignore_unused_8hpp_source.xhtml#l00014">IgnoreUnused.hpp:14</a></div></div>
<div class="ttc" id="_assert_8hpp_xhtml_a91c4dfde57907d7698c7531785690a7f"><div class="ttname"><a href="_assert_8hpp.xhtml#a91c4dfde57907d7698c7531785690a7f">ARMNN_ASSERT_MSG</a></div><div class="ttdeci">#define ARMNN_ASSERT_MSG(COND, MSG)</div><div class="ttdef"><b>Definition:</b> <a href="_assert_8hpp_source.xhtml#l00015">Assert.hpp:15</a></div></div>
<div class="ttc" id="classarmnn_utils_1_1_data_layout_indexed_xhtml"><div class="ttname"><a href="classarmnn_utils_1_1_data_layout_indexed.xhtml">armnnUtils::DataLayoutIndexed</a></div><div class="ttdoc">Provides access to the appropriate indexes for Channels, Height and Width based on DataLayout...</div><div class="ttdef"><b>Definition:</b> <a href="_data_layout_indexed_8hpp_source.xhtml#l00017">DataLayoutIndexed.hpp:17</a></div></div>
<div class="ttc" id="namespacearmnn_xhtml_a56943a0946e5f15e5e58054b8e7a04a4adb033d2f81b68f9a17e8f62de69fed4a"><div class="ttname"><a href="namespacearmnn.xhtml#a56943a0946e5f15e5e58054b8e7a04a4adb033d2f81b68f9a17e8f62de69fed4a">armnn::LayerType::Convolution2d</a></div></div>
<div class="ttc" id="_assert_8hpp_xhtml_a5698be69cbd5dfe6c28fcd9867e8cbed"><div class="ttname"><a href="_assert_8hpp.xhtml#a5698be69cbd5dfe6c28fcd9867e8cbed">ARMNN_ASSERT</a></div><div class="ttdeci">#define ARMNN_ASSERT(COND)</div><div class="ttdef"><b>Definition:</b> <a href="_assert_8hpp_source.xhtml#l00014">Assert.hpp:14</a></div></div>
<div class="ttc" id="namespacearmnn_xhtml_a56943a0946e5f15e5e58054b8e7a04a4af97adbfc88b7012a0243215b1076e7e7"><div class="ttname"><a href="namespacearmnn.xhtml#a56943a0946e5f15e5e58054b8e7a04a4af97adbfc88b7012a0243215b1076e7e7">armnn::LayerType::DepthwiseConvolution2d</a></div></div>
<div class="ttc" id="namespacearmnn_xhtml_a56943a0946e5f15e5e58054b8e7a04a4ae4743c3ec15d1d84169b17264634692e"><div class="ttname"><a href="namespacearmnn.xhtml#a56943a0946e5f15e5e58054b8e7a04a4ae4743c3ec15d1d84169b17264634692e">armnn::LayerType::BatchNormalization</a></div></div>
<div class="ttc" id="namespacearmnn_xhtml_ad1d5cce2d9e9a5d61c243e5c989112e0ad066db54b89b0912e7e7c6da51e2da51"><div class="ttname"><a href="namespacearmnn.xhtml#ad1d5cce2d9e9a5d61c243e5c989112e0ad066db54b89b0912e7e7c6da51e2da51">armnn::DataLayout::NHWC</a></div></div>
</div><!-- fragment -->
</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>src/armnn/optimizations/<a class="el" href="_fuse_batch_norm_8hpp_source.xhtml">FuseBatchNorm.hpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacearmnn.xhtml">armnn</a></li><li class="navelem"><a class="el" href="namespacearmnn_1_1optimizations.xhtml">optimizations</a></li><li class="navelem"><a class="el" href="classarmnn_1_1optimizations_1_1_fuse_batch_norm.xhtml">FuseBatchNorm</a></li>
    <li class="footer">Generated on Wed Nov 25 2020 09:59:20 for ArmNN by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
